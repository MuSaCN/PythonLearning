# Author:Zhang Yuan
from MyPackage import *
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import seaborn as sns
import statsmodels.api as sm
from scipy import stats

#------------------------------------------------------------
__mypath__ = MyPath.MyClass_Path("\\Deep-Learning-with-TensorFlow-book")  # è·¯å¾„ç±»
myfile = MyFile.MyClass_File()  # æ–‡ä»¶æ“ä½œç±»
myword = MyFile.MyClass_Word()  # wordç”Ÿæˆç±»
myexcel = MyFile.MyClass_Excel()  # excelç”Ÿæˆç±»
mytime = MyTime.MyClass_Time()  # æ—¶é—´ç±»
myplt = MyPlot.MyClass_Plot()  # ç›´æ¥ç»˜å›¾ç±»(å•ä¸ªå›¾çª—)
mypltpro = MyPlot.MyClass_PlotPro()  # Ploté«˜çº§å›¾ç³»åˆ—
myfig = MyPlot.MyClass_Figure(AddFigure=False)  # å¯¹è±¡å¼ç»˜å›¾ç±»(å¯å¤šä¸ªå›¾çª—)
myfigpro = MyPlot.MyClass_FigurePro(AddFigure=False)  # Figureé«˜çº§å›¾ç³»åˆ—
mynp = MyArray.MyClass_NumPy()  # å¤šç»´æ•°ç»„ç±»(æ•´åˆNumpy)
mypd = MyArray.MyClass_Pandas()  # çŸ©é˜µæ•°ç»„ç±»(æ•´åˆPandas)
mypdpro = MyArray.MyClass_PandasPro()  # é«˜çº§çŸ©é˜µæ•°ç»„ç±»
myDA = MyDataAnalysis.MyClass_DataAnalysis()  # æ•°æ®åˆ†æç±»
# myMql = MyMql.MyClass_MqlBackups() # Mqlå¤‡ä»½ç±»
# myMT5 = MyMql.MyClass_ConnectMT5(connect=False) # Pythoné“¾æ¥MetaTrader5å®¢æˆ·ç«¯ç±»
# myDefault = MyDefault.MyClass_Default_Matplotlib() # matplotlibé»˜è®¤è®¾ç½®
# myBaidu = MyWebCrawler.MyClass_BaiduPan() # Baiduç½‘ç›˜äº¤äº’ç±»
# myImage = MyImage.MyClass_ImageProcess()  # å›¾ç‰‡å¤„ç†ç±»
myBT = MyBackTest.MyClass_BackTestEvent()  # äº‹ä»¶é©±åŠ¨å‹å›æµ‹ç±»
myBTV = MyBackTest.MyClass_BackTestVector()  # å‘é‡å‹å›æµ‹ç±»
myML = MyMachineLearning.MyClass_MachineLearning()  # æœºå™¨å­¦ä¹ ç»¼åˆç±»
mySQL = MyDataBase.MyClass_MySQL(connect=False)  # MySQLç±»
mySQLAPP = MyDataBase.MyClass_SQL_APPIntegration()  # æ•°æ®åº“åº”ç”¨æ•´åˆ
myWebQD = MyWebCrawler.MyClass_QuotesDownload(tushare=False)  # é‡‘èè¡Œæƒ…ä¸‹è½½ç±»
myWebR = MyWebCrawler.MyClass_Requests()  # Requestsçˆ¬è™«ç±»
myWebS = MyWebCrawler.MyClass_Selenium(openChrome=False)  # Seleniumæ¨¡æ‹Ÿæµè§ˆå™¨ç±»
myWebAPP = MyWebCrawler.MyClass_Web_APPIntegration()  # çˆ¬è™«æ•´åˆåº”ç”¨ç±»
myEmail = MyWebCrawler.MyClass_Email()  # é‚®ç®±äº¤äº’ç±»
myReportA = MyQuant.MyClass_ReportAnalysis()  # ç ”æŠ¥åˆ†æç±»
myFactorD = MyQuant.MyClass_Factor_Detection()  # å› å­æ£€æµ‹ç±»
myKeras = MyDeepLearning.MyClass_Keras()  # Kerasç»¼åˆç±»
myTensor = MyDeepLearning.MyClass_TensorFlow()  # Tensorflowç»¼åˆç±»
#------------------------------------------------------------

# éœ€ä»ä¹¦ä¸Šæ‘˜å–ä»£ç 
import tensorflow as tf
a = 1.2 # python è¯­è¨€æ–¹å¼åˆ›å»ºæ ‡é‡
aa = tf.constant(1.2) # TF æ–¹å¼åˆ›å»ºæ ‡é‡
type(a), type(aa), tf.is_tensor(aa)
x = tf.constant([1, 2., 3.3])
a = tf.constant([1.2]) # åˆ›å»ºä¸€ä¸ªå…ƒç´ çš„å‘é‡
a, a.shape
a = tf.constant([1,2, 3.]) # åˆ›å»º 3 ä¸ªå…ƒç´ çš„å‘é‡
a, a.shape


a = tf.constant('Hello, Deep Learning.') # åˆ›å»ºå­—ç¬¦ä¸²
# åœ¨ tf.strings æ¨¡å—ä¸­ï¼Œæä¾›äº†å¸¸è§çš„å­—ç¬¦ä¸²ç±»å‹çš„å·¥å…·å‡½æ•°ï¼Œå¦‚å°å†™åŒ– lower()ã€æ‹¼æ¥join()ã€é•¿åº¦ length()ã€åˆ‡åˆ† split()ç­‰ã€‚
tf.strings.lower(a)

a = tf.constant(True) # åˆ›å»ºå¸ƒå°”ç±»å‹æ ‡é‡
a = tf.constant([True, False]) # åˆ›å»ºå¸ƒå°”ç±»å‹å‘é‡
a = tf.constant(True) # åˆ›å»º TF å¸ƒå°”å¼ é‡
a is True # TF å¸ƒå°”ç±»å‹å¼ é‡ä¸ python å¸ƒå°”ç±»å‹æ¯”è¾ƒ
a == True # ä»…æ•°å€¼æ¯”è¾ƒ

tf.constant(123456789, dtype=tf.int16)
tf.constant(123456789, dtype=tf.int32)
import numpy as np
np.pi # ä» numpy ä¸­å¯¼å…¥ pi å¸¸é‡
tf.constant(np.pi, dtype=tf.float32) # 32 ä½
tf.constant(np.pi, dtype=tf.float64) # 64 ä½
print('before:',a.dtype) # è¯»å–åŸæœ‰å¼ é‡çš„æ•°å€¼ç²¾åº¦
if a.dtype != tf.float32: # å¦‚æœç²¾åº¦ä¸ç¬¦åˆè¦æ±‚ï¼Œåˆ™è¿›è¡Œè½¬æ¢
    a = tf.cast(a,tf.float32) # tf.cast å‡½æ•°å¯ä»¥å®Œæˆç²¾åº¦è½¬æ¢
print('after :',a.dtype) # æ‰“å°è½¬æ¢åçš„ç²¾åº¦

a = tf.constant(np.pi, dtype=tf.float16) # åˆ›å»º tf.float16 ä½ç²¾åº¦å¼ é‡
tf.cast(a, tf.double) # è½¬æ¢ä¸ºé«˜ç²¾åº¦å¼ é‡

# TensorFlow å¢åŠ äº†ä¸€ç§ä¸“é—¨çš„æ•°æ®ç±»å‹æ¥æ”¯æŒæ¢¯åº¦ä¿¡æ¯çš„è®°å½•ï¼štf.Variableã€‚tf.Variable ç±»å‹åœ¨æ™®é€šçš„å¼ é‡ç±»å‹åŸºç¡€ä¸Šæ·»åŠ äº† nameï¼Œtrainable ç­‰å±æ€§æ¥æ”¯æŒè®¡ç®—å›¾çš„æ„å»ºã€‚
a = tf.constant([-1, 0, 1, 2]) # åˆ›å»º TF å¼ é‡
aa = tf.Variable(a) # è½¬æ¢ä¸º Variable ç±»å‹
aa.name, aa.trainable # Variable ç±»å‹å¼ é‡çš„å±æ€§
a = tf.Variable([[1,2],[3,4]]) # ç›´æ¥åˆ›å»º Variable å¼ é‡

tf.zeros([]),tf.ones([]) # åˆ›å»ºå…¨ 0ï¼Œå…¨ 1 çš„æ ‡é‡
tf.ones([3, 2])
tf.zeros_like(a) # åˆ›å»ºä¸€ä¸ªä¸ a å½¢çŠ¶ç›¸åŒï¼Œä½†æ˜¯å…¨ 0 çš„æ–°çŸ©é˜µ
tf.ones_like(a) # åˆ›å»ºä¸€ä¸ªä¸ a å½¢çŠ¶ç›¸åŒï¼Œä½†æ˜¯å…¨ 1 çš„æ–°çŸ©é˜µ
# tf.*_like æ˜¯ä¸€ç³»åˆ—çš„ä¾¿æ·å‡½æ•°ï¼Œå¯ä»¥é€šè¿‡ tf.zeros(a.shape)ç­‰æ–¹å¼å®ç°ã€‚

# é€šè¿‡ tf.fill(shape, value)å¯ä»¥åˆ›å»ºå…¨ä¸ºè‡ªå®šä¹‰æ•°å€¼ value çš„å¼ é‡
tf.fill([], -1) # åˆ›å»º-1 çš„æ ‡é‡
tf.fill([1], -1) # åˆ›å»º-1 çš„å‘é‡
tf.fill([2,2], 99) # åˆ›å»º 2 è¡Œ 2 åˆ—ï¼Œå…ƒç´ å…¨ä¸º 99 çš„çŸ©é˜µ

# é€šè¿‡ tf.random.normal(shape, mean=0.0, stddev=1.0)å¯ä»¥åˆ›å»ºå½¢çŠ¶ä¸º shapeï¼Œå‡å€¼ä¸ºmeanï¼Œæ ‡å‡†å·®ä¸º stddev çš„æ­£æ€åˆ†å¸ƒğ’©(mean,stddev 2 )ã€‚
tf.random.normal([2, 2], mean=1, stddev=2)
# é€šè¿‡ tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)å¯ä»¥åˆ›å»ºé‡‡æ ·è‡ª[minval,maxval)åŒºé—´çš„å‡åŒ€åˆ†å¸ƒçš„å¼ é‡ã€‚
tf.random.uniform([2,2],maxval=10) # åˆ›å»ºé‡‡æ ·è‡ª[0,10)å‡åŒ€åˆ†å¸ƒçš„çŸ©é˜µ

# tf.range(limit, delta=1)å¯ä»¥åˆ›å»º[0,limit)ä¹‹é—´ï¼Œæ­¥é•¿ä¸º delta çš„æ•´å‹åºåˆ—ï¼Œä¸åŒ…å« limit æœ¬èº«ã€‚
tf.range(10) # 0~10ï¼Œä¸åŒ…å« 10
tf.range(1, 10, delta=2)  # 1~10


out = tf.random.uniform([4,10]) #éšæœºæ¨¡æ‹Ÿç½‘ç»œè¾“å‡º
y = tf.constant([2,3,2,0]) # éšæœºæ„é€ æ ·æœ¬çœŸå®æ ‡ç­¾
y = tf.one_hot(y, depth=10) # one-hot ç¼–ç 
loss = tf.keras.losses.mse(y, out) # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ MSE
loss = tf.reduce_mean(loss) # å¹³å‡ MSE,loss åº”æ˜¯æ ‡é‡
print(loss)


x = tf.random.uniform([28,28],maxval=10,dtype=tf.int32)
x.shape
x = tf.expand_dims(x,axis=2) # axis=2 è¡¨ç¤ºå®½ç»´åº¦åé¢çš„ä¸€ä¸ªç»´åº¦
x.shape
x = tf.squeeze(x, axis=2) # åˆ é™¤shapeä¸­ä¸º1çš„ç»´åº¦
x = tf.random.normal([2,32,32,3])
tf.transpose(x,perm=[0,3,1,2]) # äº¤æ¢ç»´åº¦


b = tf.constant([1,2]) # åˆ›å»ºå‘é‡ b
b = tf.expand_dims(b, axis=0) # æ’å…¥æ–°ç»´åº¦ï¼Œå˜æˆçŸ©é˜µ
b = tf.tile(b, multiples=[2,1]) # é€šè¿‡å¹³é“ºä¸€ä¸ªç»™å®šçš„å¼ é‡æ¥æ„é€ ä¸€ä¸ªå¼ é‡ã€‚

